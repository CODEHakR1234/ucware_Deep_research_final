"""
Captioner â€“ ë©€í‹°ëª¨ë‹¬ ìº¡ì…˜ ìƒì„± (vLLM LLaVA | OpenAI í´ë¼ìš°ë“œ)
===========================================================
bytes ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ â†’ ìº¡ì…˜ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ (ë™ì¼ ì¸ë±ìŠ¤ ë§¤í•‘)

ì£¼ì˜: ì´ í´ë˜ìŠ¤ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì½ì§€ ì•ŠëŠ”ë‹¤. í™˜ê²½ ê¸°ë°˜ êµ¬ì„±ì€
`app/utils/captioner_factory.py`ê°€ ë‹´ë‹¹í•˜ë©°, ë³¸ í´ë˜ìŠ¤ëŠ” ì „ë‹¬ëœ
íŒŒë¼ë¯¸í„°ë¡œë§Œ ë™ì‘í•œë‹¤.
"""

from __future__ import annotations

import asyncio, base64, os
from typing import List, Literal, Optional
import httpx


class Captioner:
    """ë©€í‹°ëª¨ë‹¬ ë°°ì¹˜ ìº¡ì…”ë‹ í—¬í¼ (vLLM OpenAI ë¡œì»¬ | OpenAI í´ë¼ìš°ë“œ)."""

    def __init__(
        self,
        *,
        backend: Literal["openai_local", "openai"],
        model: str,
        api_base: Optional[str] = None,
        openai_api_key: str | None = None,
        timeout: int = 30,
        disabled: bool = False,
    ):
        # êµ¬ì„± ì €ì¥
        self.backend = backend
        self.model = model
        # ì—”ë“œí¬ì¸íŠ¸
        if backend == "openai":
            self.endpoint = api_base or "https://api.openai.com/v1"
        else:
            self.endpoint = api_base or "http://localhost:12001/v1"
        self.openai_api_key = openai_api_key or ""
        self.disabled = disabled

        self._cli = httpx.AsyncClient(timeout=timeout)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def caption(
        self,
        images: List[bytes],
        prompt: str | None = None,
        max_tokens: int = 64,
    ) -> List[str]:

        """
        Args
        ----
        images  : PNG/JPEG bytes ë¦¬ìŠ¤íŠ¸
        prompt  : VLM í”„ë¡¬í”„íŠ¸ (ê¸°ë³¸ 1-2 ë¬¸ì¥ ì„¤ëª… ìš”ì²­)
        max_tokens : ìº¡ì…˜ ìµœëŒ€ í† í°

        Returns
        -------
        List[str] : ì´ë¯¸ì§€ ìˆœì„œë¥¼ ë³´ì¡´í•œ ìº¡ì…˜ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
        """
        if not images:
            return []

        # í…ŒìŠ¤íŠ¸ìš© ìº¡ì…”ë‹ ë¹„í™œì„±í™”
        if self.disabled:
            print(f"[Captioner] âš ï¸  ìº¡ì…”ë‹ ë¹„í™œì„±í™”ë¨ (DISABLE_CAPTIONING=true)", flush=True)
            print(f"[Captioner]    ê¸°ë³¸ ìº¡ì…˜ ì‚¬ìš©: {len(images)}ê°œ ì´ë¯¸ì§€", flush=True)
            return ["ì´ë¯¸ì§€" for _ in images]

        # ìº¡ì…”ë‹ ì‹œë„ (OpenAI Chat Completions í¬ë§·)
        print(f"[Captioner] ğŸ”„ VLM í˜¸ì¶œ ì‹œì‘:", flush=True)
        print(f"[Captioner]    Backend: {self.backend}", flush=True)
        print(f"[Captioner]    Model: {self.model}", flush=True)
        print(f"[Captioner]    Endpoint: {self.endpoint}/chat/completions", flush=True)
        print(f"[Captioner]    ì´ë¯¸ì§€ ê°œìˆ˜: {len(images)}ê°œ", flush=True)
        
        try:
            prompt = prompt or "Describe this image in 1-2 sentences."

            async def _gen_one(img: bytes) -> str:
                b64 = base64.b64encode(img).decode()
                if self.backend == "openai":
                    # OpenAI í´ë¼ìš°ë“œ: Authorization í—¤ë” í•„ìš”
                    headers = {"Authorization": f"Bearer {self.openai_api_key}"}
                    payload = {
                        "model": self.model,
                        "messages": [
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}},
                                ],
                            }
                        ],
                        "max_tokens": max_tokens,
                    }
                    r = await self._cli.post(f"{self.endpoint}/chat/completions", json=payload, headers=headers)
                    r.raise_for_status()
                    data = r.json()
                    return (
                        data.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content", "")
                        .strip()
                    )
                else:
                    # vLLM OpenAI ë¡œì»¬
                    payload = {
                        "model": self.model,
                        "messages": [
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}},
                                ],
                            }
                        ],
                        "max_tokens": max_tokens,
                    }
                    r = await self._cli.post(f"{self.endpoint}/chat/completions", json=payload)
                    r.raise_for_status()
                    data = r.json()
                    return (
                        data.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content", "")
                        .strip()
                    )

            # ì—¬ëŸ¬ ì¥ ì´ë¯¸ì§€ë¥¼ ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
            results = await asyncio.gather(*(_gen_one(b) for b in images))
            
            print(f"[Captioner] âœ… VLM í˜¸ì¶œ ì„±ê³µ!", flush=True)
            print(f"[Captioner]    ìƒì„±ëœ ìº¡ì…˜ {len(results)}ê°œ", flush=True)
            
            # ìƒ˜í”Œ ìº¡ì…˜ ì¶œë ¥ (ì²˜ìŒ 2ê°œ)
            for i, caption in enumerate(results[:2], 1):
                print(f"[Captioner]    ìƒ˜í”Œ {i}: \"{caption[:60]}...\"" if len(caption) > 60 else f"[Captioner]    ìƒ˜í”Œ {i}: \"{caption}\"", flush=True)
            
            return results
            
        except Exception as e:
            print(f"[Captioner] âŒ ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨!", flush=True)
            print(f"[Captioner]    ì—ëŸ¬: {e}", flush=True)
            print(f"[Captioner]    ê¸°ë³¸ ìº¡ì…˜ ì‚¬ìš©: {len(images)}ê°œ", flush=True)
            
            # VLM ì„œë²„ ìƒíƒœ íŒíŠ¸
            if "Connection" in str(e) or "refused" in str(e).lower():
                print(f"[Captioner]    ğŸ’¡ VLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: {self.endpoint}", flush=True)
            
            # ê¸°ë³¸ ìº¡ì…˜ ë°˜í™˜
            return ["ì´ë¯¸ì§€" for _ in images]

